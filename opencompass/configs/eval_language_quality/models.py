from opencompass.models import HuggingFaceCausalLM, Llama2, OpenAI
from opencompass.models.internal import InternLMwithModule


api_meta_template = dict(
    round=[
        dict(role='HUMAN', api_role='HUMAN'),
        dict(role='BOT', api_role='BOT', generate=True)
    ],
    reserved_roles=[
        dict(role='SYSTEM', api_role='SYSTEM'),
    ],
)

base_models = [
    dict(
        abbr="baichuan_7b",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/sunyu2/baichuan-7b",
        tokenizer_kwargs=dict(trust_remote_code=True,
                            use_fast=False),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True),
        batch_padding=False,
        pad_token_id=0,
        run_cfg=dict(num_gpus=1, num_procs=1)
    ),
    dict(
        abbr="baichuan_13b",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/sunyu2/baichuan-13b",
        tokenizer_kwargs=dict(trust_remote_code=True, use_fast=False),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True),
        batch_padding=False,
        pad_token_id=0,
        run_cfg=dict(num_gpus=2, num_procs=1)
    ),
    dict(
        abbr="baichuan2_7b",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/sunyu2/baichuan2-7b",
        tokenizer_kwargs=dict(trust_remote_code=True, use_fast=False),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True),
        batch_padding=False,
        pad_token_id=0,
        run_cfg=dict(num_gpus=1, num_procs=1)
    ),
    dict(
        abbr="baichuan2_13b",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/sunyu2/baichuan2-13b",
        tokenizer_kwargs=dict(trust_remote_code=True, use_fast=False),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True),
        batch_padding=False,
        pad_token_id=0,
        run_cfg=dict(num_gpus=2, num_procs=1)
    ),
    dict(
        abbr="chatglm2",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/sunyu2/chatglm2-6b",
        tokenizer_kwargs=dict(padding_side='left',
                            truncation_side='left',
                            trust_remote_code=True,
                            use_fast=False),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True),
        batch_padding=False,  # if false, inference with for-loop without batch padding
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="chatglm3",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/sunyu2/chatglm3-6b",
        tokenizer_kwargs=dict(padding_side='left',
                            truncation_side='left',
                            trust_remote_code=True,
                            use_fast=False,
                            ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True),
        batch_padding=False,  # if false, inference with for-loop without batch padding
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
   dict(abbr="LLama2-7B",
         type=Llama2, path='/mnt/petrelfs/share_data/llm_llama/llama2_raw/llama-2-7b',
         tokenizer_path='/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model',
         max_out_len=100, max_seq_len=2048, batch_size=16, run_cfg=dict(num_gpus=1, num_procs=1)),
    dict(abbr="LLama2-13B",
         type=Llama2, path='/mnt/petrelfs/share_data/llm_llama/llama2_raw/llama-2-13b',
         tokenizer_path='/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model',
         max_out_len=100, max_seq_len=2048, batch_size=16, run_cfg=dict(num_gpus=2, num_procs=2)),    
    dict(
        abbr="qwen2-7B",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/feizhaoye/huggingface/Qwen/Qwen-7B_9_25",
        tokenizer_kwargs=dict(padding_side='left',
                            truncation_side='left',
                            trust_remote_code=True,
                            use_fast=False,
                            ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True,
                        ),
        batch_padding=False,
        pad_token_id=0,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="qwen2-14B",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/feizhaoye/huggingface/Qwen/Qwen-14B_9_25",
        tokenizer_kwargs=dict(padding_side='left',
                            truncation_side='left',
                            trust_remote_code=True,
                            use_fast=False,
                            ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True,
                        ),
        batch_padding=False,
        pad_token_id=0,
        run_cfg=dict(num_gpus=2, num_procs=1),
    ),
    dict(
        abbr="deepseek-llm-7b-base",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/sunyu2/deepseek-llm-7b-base",
        tokenizer_kwargs=dict(padding_side='left',
                            truncation_side='left',
                            ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True,
                        ),
        batch_padding=False,
        pad_token_id=100001,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),   
    dict(
        abbr="deepseek-llm-67b-base",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/sunyu2/deepseek-llm-67b-base",
        tokenizer_kwargs=dict(padding_side='left',
                            truncation_side='left',
                            ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True,
                        ),
        batch_padding=False,
        pad_token_id=100001,
        run_cfg=dict(num_gpus=8, num_procs=1),
    ),    
    dict(
        abbr="chatglm3-base",
        type=HuggingFaceCausalLM,
        path="/mnt/petrelfs/share_data/sunyu2/chatglm3-6b-base",
        tokenizer_kwargs=dict(padding_side='left',
                            truncation_side='left',
                            trust_remote_code=True,
                            use_fast=False,
                            ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True),
        batch_padding=False,  # if false, inference with for-loop without batch padding
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="qwen2-72B",
        type=HuggingFaceCausalLM,
        path="/mnt/hwfile/share_data/zhoufengzhe/model_weights/hf_hub/models--Qwen--Qwen-72B/snapshots/3c79efc9f83b018708e29835043610befcc42713",
        tokenizer_kwargs=dict(padding_side='left',
                            truncation_side='left',
                            trust_remote_code=True,
                            use_fast=False,
                            ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=16,
        model_kwargs=dict(device_map='auto', trust_remote_code=True,
                        ),
        batch_padding=False,
        pad_token_id=0,
        run_cfg=dict(num_gpus=8, num_procs=1),
    ),
]

api_models = [
    dict(abbr='GPT3.5',
        type=OpenAI, path='gpt-3.5-turbo',
        #key='',  # The key will be obtained from $OPENAI_API_KEY, but you can write down your key here as well
        meta_template=api_meta_template,
        query_per_second=1,
        max_out_len=100, max_seq_len=2048, batch_size=8),
    dict(abbr='GPT4.0',
        type=OpenAI, path='gpt-4',
        #key='',  # The key will be obtained from $OPENAI_API_KEY, but you can write down your key here as well
        meta_template=api_meta_template,
        query_per_second=1,
        max_out_len=100, max_seq_len=2048, batch_size=8),
]
