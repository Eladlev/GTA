models = [
    dict(                
        abbr="chenjingrun_1B_v401.0.0_48000",                
        type="opencompass.models.internal.InternLMwithModule",                
        path="bigdata-ckpt:s3://bigdata-ckpt/wujiang/chenjingrun_1B_v401.0.0/48000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",                
        tokenizer_type="llama",                
        module_path="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm",                
        model_config="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm/configs/chenjingrun_1B_v401.0.0.py",                
        model_type="LLAMA",                
        max_out_len=100,                
        max_seq_len=2048,                
        batch_size=8,                
        run_cfg=dict(num_gpus=1, num_procs=1),                
    ),
    dict(                
        abbr="chenjingrun_1B_v401.0.1_48000",                
        type="opencompass.models.internal.InternLMwithModule",                
        path="bigdata-ckpt:s3://bigdata-ckpt/wujiang/chenjingrun_1B_v401.0.0/48000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",                
        tokenizer_type="llama",                
        module_path="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm",                
        model_config="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm/configs/chenjingrun_1B_v401.0.1.py",                
        model_type="LLAMA",                
        max_out_len=100,                
        max_seq_len=2048,                
        batch_size=8,                
        run_cfg=dict(num_gpus=1, num_procs=1),                
    ),
]