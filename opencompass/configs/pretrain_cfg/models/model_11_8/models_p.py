from opencompass.models.internal import LLama

meta_template = dict(
    round=[
        dict(role='HUMAN', begin='<|User|>:', end='/n'),
        dict(role='BOT', begin='<|Bot|>:', end='<TOKENS_UNUSED_1>/n', generate=True),
    ],
    eos_token_id=103028)

models = [
    # dict(
    #     abbr="WXJ_Tiga_7B_v0.1.0_1000",
    #     type="opencompass.models.internal.InternLMwithModule",
    #     path="bigdata-ckp:s3://bigdata-ckpt/WXJ_Tiga_7B_v0.1.0/1000",
    #     tokenizer_path="/mnt/petrelfs/share_data/llm_model/tokenizer/llamav4.model",
    #     tokenizer_type="v4",
    #     module_path="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj",
    #     model_config="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj/configs/WXJ_Tiga_7B_v0.1.0.py",
    #     model_type="LLAMA",
    #     max_out_len=100,
    #     max_seq_len=2048,
    #     batch_size=8,
    #     run_cfg=dict(num_gpus=1, num_procs=1),
    # ),
]

models += [
    # dict(
    #     abbr="official_qianxuesen_base_500_7B_v1.0.1_37000",
    #     type="opencompass.models.internal.InternLMwithModule",
    #     path="/mnt/inspurfs/zhangshuo/ckpts/official_qianxuesen_base_500_7B_v1.0.1/37000",
    #     tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
    #     tokenizer_type="llama",
    #     module_path="/mnt/petrelfs/share_data/zhangshuo/train_internlm/",
    #     model_config="/mnt/petrelfs/share_data/zhangshuo/train_internlm/configs/official_qianxuesen_base_500_7B_v1.0.1_37000step_base_10000_fp_fp32.py",
    #     model_type="LLAMA",
    #     max_out_len=100,
    #     max_seq_len=2048,
    #     batch_size=8,
    #     run_cfg=dict(num_gpus=1, num_procs=1),
    # ),
    # dict(
    #     abbr="official_qianxuesen_7B_v1.0.1_100000",
    #     type="opencompass.models.internal.InternLMwithModule",
    #     path="/mnt/inspurfs/zhangshuo/ckpts/official_qianxuesen_7B_v1.0.1/100000",
    #     tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
    #     tokenizer_type="llama",
    #     module_path="/mnt/petrelfs/share_data/zhangshuo/train_internlm/",
    #     model_config="/mnt/petrelfs/share_data/zhangshuo/train_internlm/configs/official_qianxuesen_base_10000_7B_v1.0.1_100000step_base_500000_fp_fp32.py",
    #     model_type="LLAMA",
    #     max_out_len=100,
    #     max_seq_len=2048,
    #     batch_size=8,
    #     run_cfg=dict(num_gpus=1, num_procs=1),
    # ),
    # dict(
    #     abbr="official_qianxuesen_base_500_7B_v1.0.1_37000step_base_10000_fp_1024",
    #     type="opencompass.models.internal.InternLMwithModule",
    #     path="/mnt/inspurfs/zhangshuo/ckpts/official_qianxuesen_base_500_7B_v1.0.1_37000step_base_10000_fp/1024",
    #     tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
    #     tokenizer_type="llama",
    #     module_path="/mnt/petrelfs/share_data/zhangshuo/train_internlm/",
    #     model_config="/mnt/petrelfs/share_data/zhangshuo/train_internlm/configs/official_qianxuesen_base_500_7B_v1.0.1_37000step_base_10000_fp_fp32.py",
    #     model_type="LLAMA",
    #     max_out_len=100,
    #     max_seq_len=2048,
    #     batch_size=8,
    #     run_cfg=dict(num_gpus=1, num_procs=1),
    # ),
    # dict(
    #     abbr="official_qianxuesen_base_10000_7B_v1.0.1_100000step_base_500000_fp_1024",
    #     type="opencompass.models.internal.InternLMwithModule",
    #     path="/mnt/inspurfs/zhangshuo/ckpts/official_qianxuesen_base_10000_7B_v1.0.1_100000step_base_500000_fp/1024",
    #     tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
    #     tokenizer_type="llama",
    #     module_path="/mnt/petrelfs/share_data/zhangshuo/train_internlm/",
    #     model_config="/mnt/petrelfs/share_data/zhangshuo/train_internlm/configs/official_qianxuesen_base_10000_7B_v1.0.1_100000step_base_500000_fp_fp32.py",
    #     model_type="LLAMA",
    #     max_out_len=100,
    #     max_seq_len=2048,
    #     batch_size=8,
    #     run_cfg=dict(num_gpus=1, num_procs=1),
    # ),
    dict(
        abbr="good_7b_110000",
        type="opencompass.models.internal.InternLMwithModule",
        path="/mnt/inspurfs/share_data/llm_data/yangxiaogui/checkpoints/good_7b/110000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/v11.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b",
        model_config="/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b/configs/good_7b.py",
        model_type="BAICHUAN2",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="good_7b_130000",
        type="opencompass.models.internal.InternLMwithModule",
        path="/mnt/inspurfs/share_data/llm_data/yangxiaogui/checkpoints/good_7b/130000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/v11.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b",
        model_config="/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b/configs/good_7b.py",
        model_type="BAICHUAN2",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="good_7b_150000",
        type="opencompass.models.internal.InternLMwithModule",
        path="/mnt/inspurfs/share_data/llm_data/yangxiaogui/checkpoints/good_7b/150000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/v11.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b",
        model_config="/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b/configs/good_7b.py",
        model_type="BAICHUAN2",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="good_7b_180000",
        type="opencompass.models.internal.InternLMwithModule",
        path="/mnt/inspurfs/share_data/llm_data/yangxiaogui/checkpoints/good_7b/180000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/v11.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b",
        model_config="/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b/configs/good_7b.py",
        model_type="BAICHUAN2",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
]

models += [
    dict(
        abbr="UltraSeven_1B_v410.0.1_48000",
        type="opencompass.models.internal.InternLMwithModule",
        path="bigdata-ckpt:s3://bigdata-ckpt/wujiang/UltraSeven_1B_v410.0.0/48000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm",
        model_config="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm/configs/chenjingrun_1B_v401.0.1.py",
        model_type="LLAMA",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    # dict(abbr="LLama2-7B",
    #      type=LLama, path='/mnt/petrelfs/share_data/llm_llama/llama2_raw/llama-2-7b',
    #      tokenizer_path='/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model', tokenizer_type='llama',
    #      max_out_len=100, max_seq_len=2048, batch_size=16, run_cfg=dict(num_gpus=1, num_procs=1)),
]