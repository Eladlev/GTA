from opencompass.models.internal import LLama

meta_template = dict(
    round=[
        dict(role='HUMAN', begin='<|User|>:', end='/n'),
        dict(role='BOT', begin='<|Bot|>:', end='<TOKENS_UNUSED_1>/n', generate=True),
    ],
    eos_token_id=103028)

models = [
    # dict(
    #     abbr='good_7b_60000',
    #     type='opencompass.models.internal.InternLMwithModule',
    #     path='/mnt/inspurfs/share_data/llm_data/yangxiaogui/checkpoints/good_7b/60000',
    #     tokenizer_path='/mnt/petrelfs/share_data/yanhang/tokenizes/v11.model',
    #     tokenizer_type='llama',
    #     module_path='/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b',
    #     model_config='/mnt/petrelfs/share_data/yangxiaogui/train_internlm_good_7b/configs/good_7b.py',
    #     model_type='BAICHUAN2',
    #     max_out_len=100,
    #     max_seq_len=2048,
    #     batch_size=2,
    #     run_cfg=dict(num_gpus=1, num_procs=1)
    # ),

    # dict(
    #     abbr='7B_sft_wm_v0.15',
    #     type='opencompass.models.internal.InternLMwithModule',
    #     path='/mnt/inspurfs/gaoyang/models/7b_sft_wm_v0.15/5260',
    #     tokenizer_path='/mnt/petrelfs/share_data/yanhang/tokenizes/V7.model',
    #     tokenizer_type='v7',
    #     module_path='/mnt/petrelfs/share_data/gaoyang/InternLM_train_13b',
    #     model_config='/mnt/petrelfs/llmit/code/train_7b/InternLM/RUN/maibao_kaoshi_7_5_ST_8k_v0213rc8/09-05-19:57:40/7b_maibao_8k.py',
    #     model_type='INTERNLM',
    #     max_out_len=100,
    #     max_seq_len=2048,
    #     batch_size=1,
    #     meta_template=meta_template,
    #     run_cfg=dict(num_gpus=1, num_procs=1)
    # ),
    # dict(abbr="mistral-7b",
    #      type=LLama, path='/mnt/petrelfs/share_data/shaoyunfan/llama/mistral-7b/',
    #      tokenizer_path='/mnt/petrelfs/share_data/shaoyunfan/hf_dataset/mistral-7b/tokenizer.model', tokenizer_type='llama',
    #      max_out_len=100, max_seq_len=2048, batch_size=16, run_cfg=dict(num_gpus=1, num_procs=1)),

    # dict(
    #     abbr='fourier_v2_7B_0.0.0_5000',
    #     type='opencompass.models.internal.InternLMwithModule',
    #     path='s3://checkpoints_ssd_02/oppenheimer/fourier_v2_7B_0.0.0/5000',
    #     tokenizer_path='/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model',
    #     tokenizer_type='llama',
    #     module_path='/mnt/petrelfs/feizhaoye.dispatch/train_internlm_v0.2.0dev_10_16',
    #     model_config='/mnt/petrelfs/feizhaoye.dispatch/train_internlm_v0.2.0dev_10_16/configs/fourier_v2_7B_0.0.0.py',
    #     model_type='LLAMA',
    #     max_out_len=100,
    #     max_seq_len=2048,
    #     batch_size=16,
    #     run_cfg=dict(num_gpus=1, num_procs=1)
    # ),
]



models += [
    dict(
        abbr="chenjingrun_1B_v401.0.0_24000",
        type="opencompass.models.internal.InternLMwithModule",
        path="bigdata-ckp:s3://bigdata-ckpt/wujiang/chenjingrun_1B_v401.0.0/24000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm",
        model_config="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm/configs/chenjingrun_1B_v401.0.0.py",
        model_type="LLAMA",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="chenjingrun_1B_v401.0.0_48000",
        type="opencompass.models.internal.InternLMwithModule",
        path="bigdata-ckp:s3://bigdata-ckpt/wujiang/chenjingrun_1B_v401.0.0/48000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm",
        model_config="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm/configs/chenjingrun_1B_v401.0.0.py",
        model_type="LLAMA",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="chenjingrun_1B_v401.0.0_72000",
        type="opencompass.models.internal.InternLMwithModule",
        path="bigdata-ckp:s3://bigdata-ckpt/wujiang/chenjingrun_1B_v401.0.0/72000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm",
        model_config="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm/configs/chenjingrun_1B_v401.0.0.py",
        model_type="LLAMA",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="UltraSeven_1B_v410.0.0_24000",
        type="opencompass.models.internal.InternLMwithModule",
        path="bigdata-ckp:s3://bigdata-ckpt/wujiang/UltraSeven_1B_v410.0.0/24000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm",
        model_config="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm/configs/UltraSeven_1B_v410.0.0.py",
        model_type="LLAMA",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="UltraSeven_1B_v410.0.0_48000",
        type="opencompass.models.internal.InternLMwithModule",
        path="bigdata-ckp:s3://bigdata-ckpt/wujiang/UltraSeven_1B_v410.0.0/48000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm",
        model_config="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm/configs/UltraSeven_1B_v410.0.0.py",
        model_type="LLAMA",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        abbr="UltraSeven_1B_v410.0.0_72000",
        type="opencompass.models.internal.InternLMwithModule",
        path="bigdata-ckp:s3://bigdata-ckpt/wujiang/UltraSeven_1B_v410.0.0/72000",
        tokenizer_path="/mnt/petrelfs/share_data/yanhang/tokenizes/llama.model",
        tokenizer_type="llama",
        module_path="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm",
        model_config="/mnt/petrelfs/share_data/wujiang/internLM_repo/train_internlm/configs/UltraSeven_1B_v410.0.0.py",
        model_type="LLAMA",
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
]

models += [
    dict(                
        abbr="WXJ_Tiga_7B_v0.1.0_500",                
        type="opencompass.models.internal.InternLMwithModule",                
        path="bigdata-ckp:s3://bigdata-ckpt/WXJ_Tiga_7B_v0.1.0/500",
        tokenizer_path="/mnt/petrelfs/share_data/llm_model/tokenizer/llamav4.model",                
        tokenizer_type="v4",                
        module_path="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj",                
        model_config="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj/configs/WXJ_Tiga_7B_v0.1.0.py",                
        model_type="LLAMA",                
        max_out_len=100,                
        max_seq_len=2048,                
        batch_size=8,                
        run_cfg=dict(num_gpus=1, num_procs=1),                
    ),
    dict(                
        abbr="WXJ_Tiga_7B_v0.1.0_1000",                
        type="opencompass.models.internal.InternLMwithModule",                
        path="bigdata-ckp:s3://bigdata-ckpt/WXJ_Tiga_7B_v0.1.0/1000",
        tokenizer_path="/mnt/petrelfs/share_data/llm_model/tokenizer/llamav4.model",                
        tokenizer_type="v4",                
        module_path="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj",                
        model_config="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj/configs/WXJ_Tiga_7B_v0.1.0.py",                
        model_type="LLAMA",                
        max_out_len=100,                
        max_seq_len=2048,                
        batch_size=8,                
        run_cfg=dict(num_gpus=1, num_procs=1),                
    ),
    dict(                
        abbr="WXJ_Tiga_7B_v0.1.0_2000",                
        type="opencompass.models.internal.InternLMwithModule",                
        path="bigdata-ckp:s3://bigdata-ckpt/WXJ_Tiga_7B_v0.1.0/2000",
        tokenizer_path="/mnt/petrelfs/share_data/llm_model/tokenizer/llamav4.model",                
        tokenizer_type="v4",                
        module_path="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj",                
        model_config="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj/configs/WXJ_Tiga_7B_v0.1.0.py",                
        model_type="LLAMA",                
        max_out_len=100,                
        max_seq_len=2048,                
        batch_size=8,                
        run_cfg=dict(num_gpus=1, num_procs=1),                
    ),
    dict(                
        abbr="WXJ_Tiga_7B_v0.1.0_3000",                
        type="opencompass.models.internal.InternLMwithModule",                
        path="bigdata-ckp:s3://bigdata-ckpt/WXJ_Tiga_7B_v0.1.0/3000",
        tokenizer_path="/mnt/petrelfs/share_data/llm_model/tokenizer/llamav4.model",                
        tokenizer_type="v4",                
        module_path="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj",                
        model_config="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj/configs/WXJ_Tiga_7B_v0.1.0.py",                
        model_type="LLAMA",                
        max_out_len=100,                
        max_seq_len=2048,                
        batch_size=8,                
        run_cfg=dict(num_gpus=1, num_procs=1),                
    ),
    dict(                
        abbr="WXJ_Tiga_7B_v0.1.0_4000",                
        type="opencompass.models.internal.InternLMwithModule",                
        path="bigdata-ckp:s3://bigdata-ckpt/WXJ_Tiga_7B_v0.1.0/4000",
        tokenizer_path="/mnt/petrelfs/share_data/llm_model/tokenizer/llamav4.model",                
        tokenizer_type="v4",                
        module_path="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj",                
        model_config="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj/configs/WXJ_Tiga_7B_v0.1.0.py",                
        model_type="LLAMA",                
        max_out_len=100,                
        max_seq_len=2048,                
        batch_size=8,                
        run_cfg=dict(num_gpus=1, num_procs=1),                
    ),
    dict(                
        abbr="WXJ_Tiga_7B_v0.1.0_5000",                
        type="opencompass.models.internal.InternLMwithModule",                
        path="bigdata-ckp:s3://bigdata-ckpt/WXJ_Tiga_7B_v0.1.0/5000",
        tokenizer_path="/mnt/petrelfs/share_data/llm_model/tokenizer/llamav4.model",                
        tokenizer_type="v4",                
        module_path="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj",                
        model_config="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj/configs/WXJ_Tiga_7B_v0.1.0.py",                
        model_type="LLAMA",                
        max_out_len=100,                
        max_seq_len=2048,                
        batch_size=8,                
        run_cfg=dict(num_gpus=1, num_procs=1),                
    ),
    dict(                
        abbr="WXJ_Tiga_7B_v0.1.0_6000",                
        type="opencompass.models.internal.InternLMwithModule",                
        path="bigdata-ckp:s3://bigdata-ckpt/WXJ_Tiga_7B_v0.1.0/6000",
        tokenizer_path="/mnt/petrelfs/share_data/llm_model/tokenizer/llamav4.model",                
        tokenizer_type="v4",                
        module_path="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj",                
        model_config="/mnt/petrelfs/share_data/leizhikai/wxj/train_internlm_wxj/configs/WXJ_Tiga_7B_v0.1.0.py",                
        model_type="LLAMA",                
        max_out_len=100,                
        max_seq_len=2048,                
        batch_size=8,                
        run_cfg=dict(num_gpus=1, num_procs=1),                
    ),
]